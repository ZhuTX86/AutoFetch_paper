# 自动化文献追踪报告

> **搜索词**: `Large Language Models + Reasoning` | **时间范围**: 2025-2026 | **更新时间**: 2026-02-02 10:58

| 发表时间/来源 | 论文题目 | 摘要摘要 | 链接 |
| :--- | :--- | :--- | :--- |
| L Luo, J Ju, B Xiong, YF Li, G Haffari, S Pan - Pacific-Asia Conference on …, 2025 - Springer | **ChatRule: Mining Logical Rules with Large Language Models for Knowledge Graph Reasoning** | … To harness the semantics understanding ability of large language models (LLMs), we propose an LLM-based rule generator that leverages both the semantics and structural information … | [查看详情](https://link.springer.com/chapter/10.1007/978-981-96-8173-0_25) |
| X Tan, X Wang, Q Liu, X Xu, X Yuan… - Proceedings of the ACM …, 2025 - dl.acm.org | **Paths-over-graph: Knowledge graph empowered large language model reasoning** | … Large Language Models (LLMs) have achieved impressive … especially in deep complex reasoning and knowledge-intensive … knowledge for reasoning. However, existing KG-based LLM … | [查看详情](https://dl.acm.org/doi/abs/10.1145/3696410.3714892) |
| X Tang, T Hu, M Ye, Y Shao, X Yin… - The Thirteenth …, 2025 - openreview.net | **Chemagent: Self-updating memories in large language models improves chemical reasoning** | … Our research presents a novel approach to enhancing large language models for solving complex chemical problems through self-exploration and memory formation. This method … | [查看详情](https://openreview.net/forum?id=kuhIqeVg0e) |
| TR Wei, H Liu, X Wu, Y Fang - arXiv preprint arXiv:2502.14333, 2025 - arxiv.org | **A survey on feedback-based multi-step reasoning for large language models on mathematics** | … large language models (LLM) found chain-of-thought prompting strategies to improve the reasoning … Therefore, subsequent research aimed to integrate the multi-step reasoning process … | [查看详情](https://arxiv.org/abs/2502.14333) |
| G Zhou, P Qiu, C Chen, J Wang, Z Yang, J Xu… - arXiv preprint arXiv …, 2025 - arxiv.org | **Reinforced mllm: A survey on rl-based reasoning in multimodal large language models** | … LLMs, reasoning tasks in multi-modal large language models (… mechanisms to generate large volumes of reasoning data and … -based reasoning for Multimodal Large Language Models (… | [查看详情](https://arxiv.org/abs/2504.21277) |
| B Zhang, Y Liu, X Dong, Y Zang, P Zhang… - arXiv preprint arXiv …, 2025 - arxiv.org | **Booststep: Boosting mathematical capability of large language models via improved single-step reasoning** | … Large language models (LLMs) have … reasoning errors in fine-grained steps. Moreover, ICL examples retrieved at the question level may omit critical steps or even mislead the model … | [查看详情](https://arxiv.org/abs/2501.03226) |
| Y Chen, VK Singh, J Ma, R Tang - arXiv preprint arXiv:2502.11008, 2025 - arxiv.org | **Counterbench: A benchmark for counterfactuals reasoning in large language models** | … In this paper, we evaluate the performance of large language models (LLMs) in counterfactual rea… tual reasoning poses a significant challenge for LLMs, with most models performing at … | [查看详情](https://arxiv.org/abs/2502.11008) |
| H Kim, M Sclar, T Zhi-Xuan, L Ying, S Levine… - arXiv preprint arXiv …, 2025 - arxiv.org | **Hypothesis-driven theory-of-mind reasoning for large language models** | … -tracing, an inference-time reasoning algorithm designed to trace the mental states … reasoning models - eg, o1 and R1 - on theory-of-mind, highlighting the difference of social reasoning … | [查看详情](https://arxiv.org/abs/2502.11881) |
| Z Zheng, N Rampal, TJ Inizan, C Borgs… - Nature Reviews …, 2025 - nature.com | **Large language models for reticular chemistry** | … using chain-of-thought reasoning (bottom); external data and tool augmentation (part d), which expands large language model capabilities by accessing external databases for real-time … | [查看详情](https://www.nature.com/articles/s41578-025-00772-8) |
| MA Mersha, MG Yigezu, J Kalita - Knowledge-Based Systems, 2025 - Elsevier | **Evaluating the effectiveness of XAI techniques for encoder-based language models** | … Human-reasoning Agreement … models, significantly excelling in HA with a score of 0.9685 on DeBERTa-xlarge, robustness, and consistency as the complexity of large language models … | [查看详情](https://www.sciencedirect.com/science/article/pii/S0950705125000899) |